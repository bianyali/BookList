#+TITLE: [[mitpress.mit.edu/scip][Structure and Interpretation of Computer Programs]]

* TIME

  1. 2015年01月28日 - CONTINUE




* Building Abstraction with Procedures

** COMMNET

  1. 代码就是精确的思维
     代码并不是让计算机干什么，而是自己的精确的想法，即使没有计算机，也可以明白自己的想法。 计算机只不过是能够理解并精确的执行这种想法。

  2. 将思想写下来
     人们的行为，如果只是凭感觉去做，那永远不能对这种思想熟悉得掌握。 只有将这种思想写下来，才是真正得掌握她。 如果这种思想，针对的是同一种数据结构，那么这种思想可以扩展开来。如果这种思想，对应到不同的数据上面，也就不能将这种思想适用开来。

  3. 操纵世界的program
     现在的code只能操纵数据，操纵信息，如果将program和复杂得机器结合起来，就可以操纵环境。

  4. 语言等效性
     根据语言的等效性，所有的语言实现得功能，另外一种语言也是肯定能够实现得，只是代码量得问题而已。 所以，系统可以适用汇编，可以是机器码，可以是c-lang，都可以将上面得语言编译成这类底层的语言。

  5. 语言的核心
     语言的核心是procedure and data，将 data 全部用 list 代表，将 procedure 全部用 list 代表，具体的 list 代表方式，不同就是不同的 lisp 方言核心。 各种不同的基础的数据类型，都可以用list表示。 然后统一的算法，来统一自己的思想。
     In this chaper we will deal only with simple numberical data so that we can focus on the rules for building procedures. In later chapers, we will see that these same rules allow us to build procedures to manipulate compound data as well.
     语法核心需要有一些 primitive data and primitive procedure process these datal. 通常，programming 的primitive 都是 数值，boolean，string 相关的数据。 但是，programing language 可以有，也可以规定，其他的atom。
     Expression represanting numbers may be combined with an expression representing a primitive procedure to form a compound expression that represents the application of the procedure to those numbers.
     对于数据的操作，对于procedure，就应该有两种东西，(operater data data data)

  6. 关于special form
     可不可以不将这些special form 放到 括号里面，而括号里面的都是 combination 类型的执行方式。

  7. recursion and pattern recognation
     都是为了实现对了事物的认识，然后对于这个事物的特征，提供解决方案。 如果这个事物是无规则的，也就是没有特征的，也就无法进行模式识别，也就无法进行recursion。 最复杂的模式也就是正则表达式，最复杂的正则表达式可以使用recursion来解决。一般的最简单的事物的模式，也就是最简单的重复，对于这种最简单的重复，也就是使用iteration来对付就可以了。

  8. lambda 本来就是 primitive

     对于产生函数的expression，虽然有了理解，但是始终感觉执行产生了什么东西，有些疑问，毕竟，记住一个数字，一个data，是比较容易的，虽然也是比较抽象的，但是，我已经习惯了 1 2 3 等这类的data的抽象，而让我记忆，甚至连理解一个lambda表达式确实有些看着不顺眼。
     lambda 把它当成 atom, 它和其他data相同，本来就是 data， 只有当他存在于 expression 中的第一个位置的时候，才是要执行的procedure：
     (lambda (x) x) ; 就是一种与众不同，独一无二的数据，一种思想形容方式
     ((lambda (x) x) x) ; 将 lambda 进行解析，这是，就是进行substitution的时候。
     这样进行对lambda的理解也就正确了。

  9. 函数的含义
     对于世界问题的解决，就是将问题进行模式识别，对于不同的模式进行不同的处理。当然，既然要进行模式识别，说明这个世界被定义为问题的东西是有规则的，即使这个规则多么的杂乱无章。 对于这个有规则的东西，其中的一个规则，我们可以用一个函数来进行描述和解决。 对于一个这个小规则的大规则，我们用一个包含这个函数的算子，也就是高阶函数来表示。 然后这样一直下去，就可以实现整个问题的解决了。 也就是说，函数，是对于正则表达式的现实生活问题的解决。 谁能够好的实现这个抽象，谁就能够好的解决现实问题。 如果遇到的困难，都不能描述出来，这是个什么问题，你怎么解决呢？ 也就不存在所谓的算法了。。。

  10. Functional Programming
      函数式编程 (Functional programming) 或者是函数程序设计，又称为泛函编程，是一种编程范式，他讲电脑运算视为数学上的函数计算，并且避免使用程序状态以及易变对象。 函数编程语言最重要的基础就是lambda演算(lambda calculus). 而且lambda演算的函数可以接受函数当做输入和输出。
      和命令式编程相比，函数式编程强调程序的执行结果比执行过程更重要，倡导利用若干简单的执行单元让计算结果不断渐进，逐层推到复杂的运算，而不是设计一个复杂的执行过程。

      为什么有括号，每个括号，代表一层访问是从哪里开始的，执行是在那一层。 对于数据来说，括号，代表的是层次，是更加标准的对于数据的描述。 对于程序来说，括号是运算的孙逊，一定要这么理解，比如(+ (* 1 2) 3), 这样，是个人都知道他的运算顺序. 只有一个潜规则就行： 执行是从外括号向内括号扩展的。 而 1*2+3*4， 这只能进行分析，告诉电脑如何分析才行，简直就是过度设计的结果。

** QUOTE

    1. what matter
       It doesn't matter much what the programs are about or what applications they server. what does matter is how well they perform and how smoothly they fit with other programs in the creation of still greater programs.

    2. A computer is like a violin
       A computer is like a violin. You can imagine a novice trying first a phonograph and then a violin.

    3. how to make general ideas?
       The acts of the mind, wherein it exerts its power over simple ideas, are chiefly three:
       1. Combining several simple ideas into one compound one, and thus all complex ideas are made.
       2. The second is bringing two ideas, whether simple or complex, together, and setting them by one another so as to take a view of them at one, by which it gets all its ideas of relations.
       3. The third is separating them from all other ideas that accompany them in their real existence: this is called abtraction, and thus all its general ideas are made.

    4. sorcerer's spell
       The programs we use to conjure processes are like a sorcerer's spells. They are carefully composed from symbolic expressions in arcane and esoteric programming languages that prescribe the tasks we want our processes to perform.

    5. The Elements of Programming
       A powerful programming language is more than just a means for instructing a computer to perform tasks. The language also serves as a framework within which we organize our ideas about processes. Thus, when we describe a language, we should pay particular attention to the means that the language provides for combining simple ideas to form complex ideas. Every powerful language has three mechanisms for accomplishing this:

       1. primitive expressions, which represent the simplest entities the language is convernted with,
       2. means of combination, by which compound elements are built from simpler ones, and
       3. means of abstraction, by which compound elements can be named and manipulated as units.

       In programming, we deal with two kinds of elements: procedures and data. (Later we will discover that they are really not so distincinct). Informally, data is "stuff" that we want to manipulate, and procedures are descriptions of the rules for manipulating the data. Thus, any powerful programming language should be able to describe primative data and primative procedures and should have methods for combining and abstracting procedures and data.

    6. Combinations
       Expressions such as these, formed by delimiting a list of expressions within parentheses in order to denote application, are called combinations. The leftmost element in the list is called the operator, and the other elements are called operands. and the other elements are called operands. The value of a combination is obtained by applying the procedure specified by the ooperator to the arguments that are the values of the operands.

    7. name
       A critical aspect of programming language is the means it provide for using names to refer to computational object. We say that the name identifies a variable whose value is the object.

    8. define
       In the Scheme dialect of Lisp, we name things with define.
       In this book, we do not show the interpreter's response to evaluating definitions, since this is highly implementation-dependent.
       In general, computational objects may have very complex structures, and it would be extremly inconvenient to have to remember and repeat their details each time we want to use them. Indeed, complex programs are contructed by building, step by step, computational objects of increasing complexity. The interpreter makes this step-by-step program construction particularly convenient because name-object associations can be created incrementally in successive interactions.

    9. Compound procedures
       Compound procedures are used in exactly the same way as primitive procedures. Indeed, one could not tell by looking at the definition of square given above whether square was built into the interpreter, like + and *, or defined as a compound procedure.

    10. Substitution model
        The process we have just described is called the substitution model for procedure application. It can be taken as a model that determines the "meaning" of procedure application, insofar as the procedures in this chapter are concerned. However, there are two points that should be stressed:
        * The purpose of the substitution is to help us think about procedure application, not to provide a description of how the interpreter really works. Typical interpreters do not evaluate procedure applications by manipulating the text of a procedure to substitute values for the formal parameters. In practice, the "substitution" is accomplished by using a local environment for the formal parameters. We will discuss this more fully in Chaper 3 and Chapter 4 when we examine the implementation of an interpreter in detail.
        * Over the course of this book, we will present a sequence of increasingly elaborate models of how interpreters work, culminating with a complete implementation of an interpreter and compiler in Chpter 5. The substitution model is only the first of these models -- a way to get started thinking formally about evaluating process. In general, when modeling phenomena in science and engineering, we begin with simplifed, incomplete models. As we examine things in greater detail, these simple models become inadequate and must be replaced by more refined models. The substitution model is no exception. In particular, when we address in Chaper 3 the use of procedures with "mutable data", we will see that the substitution model breaks down and must be replaced by a more complicated model of procedure application.

    11. Special form
        Notice that "and" and "or" are special forms, not procedures, because the subexpressions are not necessarily all evaluated. "not" is an ordinary procedure.

    12. Procedures and functions
        Procedures, as introduced above, are much like ordinary mathematical functions. They specify a value that is determined by one or more parameters. But there is an important difference between mathematical functions and computer procedures. Procedures must be effective.
        The contrast between function and procedure is a reflection of the general distinction between describing properties of things and describing how to do things, or, as it it sometimes referred to, the distinction between declarative knowledge and imperative knowledge. In mathmatics we are usually concerned with declarative (waht is) descriptions, whereas in computer science we usually concerned with imperative (how to) descriptions.

    13. Declative and imperative descriptions
        Declative and imperative descriptions are intimately related, as indeed are mathematics and computer science. For instance, to say that the answer produced by a program is "correct" is to make a declarative statement about the program. There is a large amount of research aimed at establishing techniques for proving that programs are correct, and much of the technical difficulty of this subject has to do with negotiating the transition between imperative statements (from which programs are constructed) and declarative statements (which can be used to deduce things). In a relative vein, an important current area in programming-language design is exploration of so-called very high-level language, in which one actually programs in terms of declarative statements. The idea is to make interpreters sophisticated enough so that, given "what is" knowledge specified by the programmer, they can generate "how to" knowledge automatically. This cannot be done in general, but there are important areas where progress has been made. We shall revisit the idea in Chaper 4.

    14. Tail recursion
        Readers who are worried about the efficiency issues involved in using procedure calls to implement iteration should note the remark on "tail recursion" in Secion 1.2.1

    15. Block structure
        Embeded definitions must come first in a procedure body. The management is not responsible for the consequences of running programs that interwine definition and use.

    16. In addition to Elements of programming
        We have now considered elements of programming: We have used primitive arithmetic operations, we have combined these operations, and we have abstracted these composite operations by defining them as compound procedures. But that is not enough to enable us to say that we know how to program. Our situation is analogous to that of someone who has  learned the rules for how the pieces move in chess but knows nothing of typical openings, tactics, or strategy. Like the novice chess player, we don't yet know the common patterns of usage in the domain. We lack the knowledge of which moves are worth making (which procedures are worth defining). We lack the experience to predict the consequences of making a move (executing a procedure).
        The ability to visualize the consequences of the actions under consideration is crucial to becoming an expert programmer, just as it is in any synthetic, creative activity.
        So it is with programming, where we are planning the course of action to be taken by a process and where we control the process by means of a program. To become experts, we must learn to visulize the processes generated by various types of procedures. Only after we have developed such a skill can we learn to reliably construct programs that exhibit the desired behavior.

    17. Procedure
        A procedure is a pattern for the local evolution of a computational process. It specifies how each stage of the process is built upon the previous stage.

    18. Iterative process
        In general, an iterative process is one whose state can be summarized by a fixed number of state variables, together with a fixed rule that describes how the state variables should be updated as the process moves from state to state and an (optional) end test that specifies conditions under which the process should terminate. In computing n!, the number of steps required grows linearly with n. Such a process is called linear iterative process.

    19. Recursive process
        Consider the first process. The substitution model reveals a shape of expasion followed by contraction. The expansion occurs as the process builds up a chain of deferred operations (in this case, a chain of multiplications). The contraction occurs as the operations are actually performs. This type of process, characterized by a chain of deferred operations, is called a recursive process. Carrying out this process requires that the interpreter keep track of the operations to be performed later on. In the computation of n!, the length of the chain of deferred multiplications, and hence the amount of information needed to keep track of it, grows linearly with n (is proportional to n), just like the number of steps. Such a process is called a linear recursive process.

    20. Recursive VS. Iterative
        Ihe contrast between the two processes can be seen in another way. In the iterative case, the program variables provide a complete description of the state of the process at any point. If we stopped the computation between steps, all we would need to do to resume the computation is to supply the interpreter with the values of the three program variables. Not so with the recursive process. In this case there is some additional "hidden" information, maintained by the interpreter and not contained in the program variables, which indicates "where the process is" in negotiating the chain of deferred operations. The longer the chain, the more information must be maintained.
        When we discuss the implementation of procedures on register machines in Chaper 5, we will see that any interative process can be realized "in hardware" as a machine that has a fixed set of regiesters and no auxiliary memory. In contrast, realizing a recursive process requires a machine that uses an auxiliary data structure known as a stack.

    21. Recursive Process VS. Recursive Procedure
        In contrasting iteration and recursion, we must be careful not to confuse the notion of a recursive process with the notion of a recursive procedure. When we describe a procedure as recursive, we are referring to the syntactic fact that the procedure definition refers (either directly or indirectly) to the procedure itself. But when we describe a process as following a pattern that is, say, linearly recursive, we are speaking about how the process evolves, not about the syntax of how a procedure is written. It may seem disturbing that we refer to a recursive procedure such as fact-iter as generating an iteractive process. However, the process really is iterative: Its sttate is captured completely by its three state varibles, and an interpreter need keep track of only three variables in order to execute the process.
        With a tail-recursive implementation, iteration can be expressed using the ordinary procedure call mechanism, so that special iteration constructs are useful only as syntactic sugar.

    22. Tree Recursion
        Another common pattern of computation is called tree recursion. One should not conclude from this that tree-recursive processes are useless. When we consider processes that operate on hierarchically structured data rather than numbers, we will find that tree recursion is a natural and powerful tool. But even in numerical operations, tree-recursive processes can be useful in helping us to understand and design programs. For instance, although the first fib procedure is much less efficient than the second one, it is more straightforward, being little more than a translation into Lisp of the definition of the Fibonacci sequence. To formulate the iterative algorithm required noticing that the computation could be recast as an iteration with three state variables.

    23. Process and Procedure
        The process that a procedure genetates is of course dependent on the rules used by the interpreter. As an expample, we were to interpret this procedure using normal-order evaluation, or applicative-order evaluation.

    24. Procedure we need
        We have seen that procedures are, in effect, abstractions that describes compound operations on numbers independent of the particular numbers (particular numbers/parameters).

        (define (cube x) (* x x x))

        We are not talking about the cube of a particular number, but rather about a method for obtaining the cube of any number. Of course, we could get along without ever defining this procedure, by always writing expressions such as:

        (* 3 3 3)
        (* x x x)
        (* y y y)

        and never mentioning cube explicitly. This would place us at a serious disadvantage, forcing us to work always at the level of the paricular operations that happen to be primitives in the language (multiplication, in this case) rather than in terms of highter-level operations. Our programs would be able to compute cubes, but our language would lack the ability to express the concept of cubing. One of the things is the ability to build abstractions by assigning names to common patterns and then to build abstractions directly. Procedures provide this ability. This is why all but the most primitive programming languages include mechanisms for defining procedures.

    25. Higher-order Procedures
        This section shows how higher-order procedures can serve as powerful abstraction mechanisms, vastly increasing the expressive power of our language. As programmers, we should be alert to opportunities to identify the underlying abstractions in our programs and to build upon them and generalize them to create more powerful abstractions. This is not to say that one should always write programs in the most abstract way possible; expert programmers know how to choose the level of abstraction appropriate to their task. But it is important to be able to think in terms of these abstractions, so that we can be ready to apply them in new contexts. The significance of higher-order procedures is that they enable us to represent these abstractions explicitly as elements in our programming language, so that they can be handled like other putational elements.

    26. First-class
        In general, programming language impose restrictions on the ways in which computational elements can be manipulated. Elements with the fewest restrictions are said to have first-class status. Some of the "rights and privileges" of first-class elements are:
        * They may be named by variables.
        * They may be passed as arguments to procedures.
        * They may be returned as the results of procedures.
        * They may be included in data structures.

        Lisp, unlike other common programming languages, awards procedures full first status. This poses challenages for efficient implementation, but the resulting gain in expressive power is enormous.
        The major implementation cost of first-class procedures is that allowing procedures to be returned as values requires reserving storage for a procedure's free variables even while the procedure is not executing. I the Scheme implementation we will study in Section 4.1, these variables are stored in the procedure's environment.

* Building Abstraction with Data

** Introduction to Data Abstraction

  1. Procedural representation of pairs

     The point of exhibiting the procedural representation of pairs is not that our language works this way (Scheme, and Lisp systems in general, implement pairs directly, for efficiency reasons), but that it could work this way. The procedural representation, although obscure, is a perfectly adequate way to represent pairs, since it fulfills the only conditions that pairs need to fulfill. This example also demonstrates that the ability to manipulate procedures as objects automatically provides the ability to manipulate procedures as objects automatically provides the ability to represent compound data. This may seem a curiosity now, but procedural representaions of data will play a central role in our programming repertoire. This style of programming is often called message passing, and we will using it as a basic tool in Chaper 3 when we address the issues of modeling and simulation.

  2. Closure

     The ability to create pairs whose elements are pairs is the essence of list structure's importance as a representational tool. We refer to this ability as the closure porperty of cons. In general, an operation for combining data object satisfies the closure property if the results of combining  things with that operation can themselves be combined using the same operation. Closure is the key to power in any means of combination because it permits us to create hierarchical structures -- structures made up of parts, which themselves are made up of parts, and so on.

  3. Combination

     In this section, we take up the consequences of closure for compound data. We describe some conventional techniques for using pairs to represent sequences and trees, and we exhibit a graphics language that illustrates closure in a vivid way.

     The notion that a means of combination should satisfy closure is straightfoward idea. Unfortunately, the data combiners provide in many popular programming languages do not satify closure, or make closure cumbersome to exploit. In Fortran or Basic, one typically combines data elements by assembling them into arrays -- but one cannot form arrays whose elements are themselves arrays. Pascal and C admit structures whose elements are structures. However, this requires that the programmer manipulate pointers explicitly, and adhere to the restriction that each field of a structurecan contain only elements of a prespecified form. Unlike Lisp with its pairs, these languages have no built-in general-popurpose glue that makes it easy to manipulate compound data in a uniform way. This limitation lies behind Alan Perlis's comment in his foreword to this book: "In Pascal the plethora of declarble data structures induces a specialization within functions that inhibits and penalizes casual cooperation. It is better to have 100 functions operate on one data structure than to have 10 functions operate on 10 data structures."

** Hierchical Data and the Closure Property

  1. Levels of language for robust design
     We have also obtained a glimpse of another crucial idea about  languages and program design. This is the approach of stratified design, the notion that a complex system should be structured as a sequence of levels that are described using a sequence of languages. Each level is contructed by combining parts that are regarded as primitive at that level, and the parts constructed at each level are used as primitive at that level,a dn the parts constructed at each level are used as primitives at the next level. The language used at each level of a stratified design has primitives, means of combination, and means of abstraction appropriate to that level of detail

     Stratified design helps make programs robust, that is, it makes it likely that small changes in a specification will require correspondingly small changes in the program.

** Symbolic Data

  1. Symbolic Data

     为什么有括号，每个括号，代表一层访问是从哪里开始的，执行是在那一层。 对于数据来说，括号，代表的是层次，是更加标准的对于数据的描述。 对于程序来说，括号是运算的孙逊，一定要这么理解，比如(+ (* 1 2) 3), 这样，是个人都知道他的运算顺序. 只有一个潜规则就行： 执行是从外括号向内括号扩展的。 而 1*2+3*4， 这只能进行分析，告诉电脑如何分析才行，简直就是过度设计的结果。

  2. Sets as ordered lists

     将无序的数据对象，assign a unique number 来让该数据对象成为有序的，以减少查找过程中的时间消耗。One advantage of ordering shows up in element-of-set?: In checking for the presence of an item, we no longer have to scan the entire set. 默认的查找范围在缩小，缩小大到和 查找元素的大小 相关。 尽管时间复杂度还是 n 级别的，但却是减少的 一半。 接下来可以使用二分法(话说在 list set 中如何使用二分法？)，将时间复杂度变成 log(n) 级别. 但进行intersection的时候，时间复杂度变成了 n.

  3. Sets as binary trees

     二叉树，是更有序的 ordered list，就像是一个list 表现了 二分法。 不需要在 算法 procedure中实现，因为 在list 中，已经使用 binary trees 实现这种二分。
     We can do better than the ordered-list representatio by arranging the set elements in the form of a tree. Each node of the tree holds one element of the set, called the "entry" at that node, and a link to each of two other(possibly empty) nodes. The "left" link points to elements smaller than the one at the node, and the "right" link to elements greater than the one at the node.

     只有这个二叉树的层数最少时，才是使用的 二分法。 根节点，从最大最小节点的平均值的节点开始。 If the tree is "balanced", each of these subtrees will be about half the size of the original. Thus, in one step we have reduced the problem of searching a tree of size n to search a tree of size n/2. Since the size of the tree is halved at each step, we should expect that the number of steps needed to search a tree of size n grows as ø(long n). For large sets, this will be a significant speedup over the previous representations. 所谓提高查询速度，就是在查询之前，将数据整理的越加有序，越加有层次性，就更加容易查找，就像将衣服分门别类的放到衣橱中。

     万物皆是 list。 We are representing sets in terms of trees, and trees in terms of lists -- in effect, a data abstraction built upon a data abstraction.We can regard the procedures entry, left-branch, right-branch, and make-tree as a way of isolating the abstraction of a "binary tree" from the particular way we might wish to represent such a tree in terms of lsit structure.

     * balanced tree

       Searching a tree can be performed in a logarithmic number of steps rests on the assumption that the tree is "balanced", that the left and the right substree of every tree have approximately the same number of elements, so that each subtree contains about half the elements of its parent. But how can we be certain that the trees we construct will be balanced?  Even if we start with a balanced tree, adding elements with adjoin-set may produce an unbalanced result. Since the position with the items already in the set, we can expect that if we add elemts "randomly", the tree will tend to be balanced on the average. But this is not a guarantee. 要想让数据统一结构，统一规则，在每天修改元数据的时候，都要对 tree 进行重新整理。 We can perform transformations to keep our set in balance. There are also other ways to solve this problem, most of which involve designing new data structures for which searching and insertion both can be done in ø(log n) steps. Examples of such structure include B=trees and red-black trees. There is a large literature on data structures devoted to this problem. 目的都是为了，将数据，按规则整理，然后，方便快速的查询和存储。

  4. Sets and information retrieval

     We have examined options for using lists to represent sets and have seen how the choice of representation for a data object can have a large impact on the performance of the programs that use the data. Another reason for concerning on sets is that the techniques discussesd here appear again and again in applications involving information retrieval.

     * data base

       Consider a data base containning a large number of individual records, such as the personnel files for a company or the transactions in an accounting system. A typical data-management system spends a large amount of time accessing or modifying the data in the records and therefore requires an efficient method for accessing records. This is done by identifying a part of each record  to serve as an identifying key. A key can be anything that uniquely identifies the record. For a personnel file, it might be an employee's ID number. For an accounting system, it might be a transaction number. Whatever the key is, when we define the record as a data strucure we should include a key selector procedure that retrives the key associated with a given record.

     * Information-retrieval system

       Information-retrieval systems in which records have to be "randomly accessed" are typically implemented by a tree-based method, such as the binary-tree representation discuessed previously. In designing such a system the methodology of data abstraction can be a great help. (tree-based 分层的数据存储)

  5. Huffman Encoding Trees

     This section provides practice in the use of list structure and data abstraction to manipulate sets and trees.

     * Prefix Code

       Design the code in such a way that no complete code for any symbol is the beginning (or prefix) of the code for another symbol. Such a code is called a prefix code.

     * Huffman encoding method

       In general, we can attain significant savings if we use variable-length prefix codes that take advantage of the relative frequencies of the symbols in message to be encoded. One particular scheme for doing this is called the Huffman encoding method.

       平衡二叉树是对所有元素出现概率都相同时，使用的策略。 Huffman tree 针对的是每个元素出现的不同频率。

  6. Multiple Representation for Abstract Data

     The data-abstraction barriers are powerful tools for controlling complexity. By isolating the underlying representations of data objects, we can divide the task of designing a large program into smaller tasks that can be performed separately. But this kind of data is not yet powerful enough, because it may not always make sense to speak of "the underlying representation" for a data object.

     For one thing, there might be more than one useful representation for a data object, and we might like to design systems that can be deal with multiple representations.  In this section, we will learn how to cope with data that may be represented in dirrerent ways by different parts of a program. This requires constructing generic procedures -- procedures that can operate on data that may be represented in more than one way.

     * The horizontal and vertical abstraction barrier

       The "horizontal" abstraction barriers isolate "higher-level" operations from "lower-level" representations. In addition, there is a "vetical" barier that gives us the ability to separately design and install  alternative representation.

     * Tagged data

       The abstraction data barrier formed by the selectors and constructors permits us to defer to the last possible moment the choice a concrete representation for our data objects and thus retain maximum flexibility in our system design.

       The discipline of stripping off and attaching tags as data objects are passed from level to level can be an important organizational strategy.

     * Data-directed programming

       The key idea of data-directed programming is to handle generic operations in programs by dealing explicitly with operation-and-type tables.

       所谓数据导向的程序设计，是针对不同的类型数据的一集公共通用操作。也就是说，数据导向，（具有同样一组操作的不同类型的数据），不管数据的类型如何增加，都使用这组操作，因为，只要有数据类型的增加，我们只需要向 table 中添加这种数据类型，对应的相同的操作即可。

       当数据类型经常变化， 而这些变换的数据，总是有着几个统一的操作接口时，最恰当的是数据导向的程序设计。
       当数据类型固定，而这种数据类型上的操作经常添加时，消息传递方式更好。
       当数据类型比较少，数据的操作比较统一时，使用显式分派的通用类型操作比较方便（无需定义table）

     * Message passing

       As a large system with generic oiperations evolves, new types of data objects or new operations may be needed. For each of the three stragies -- generic operations with explicit dispatch, data-directed style, and message-passing-style -- describe the changes that must be made to a system in order to add new types or new operations.

  7. Systems with Generic Operations

     * Combining Data of Different Types

       We have gone to great pains to introduce barriers between parts of our programs so that they can be developed and understood separately. We would like to introduce the cross-type operations in some carefully controlled way, so that we can support them without seriously violating our module boundaries.

     * Coercion

       In the general situation of completely unrelated operations acting on completely unrelated types, implementing explicit cross-type operations, cumbersome though it may be, is the best that one can hope for. Fortunately, we can usually do better by taking advantage of additional strucure that may be latent in our type system. Often the different data types are not completely independent, and there may be ways by which objects of one type may be viewed as being another type. This process is called coercion.

       The coercion scheme has many advantages over the method of defining explicit cross-type operations, as outlined above. Although we still need to write coercion procedures to the related the types (possibly (* n n) procedures for a system with n types), we need to write only one procedure for each pair of types rather than a diffrent procedure for each collection of types and each generic operation. What we are counting on here is the fact that the appropriate transformation between types depends only on the types themselves, not on the operation to be applied.

       If we are clever, we can usually get by with fewer that (* n n) coercion procedures. For instance, if we know how to convert from type 1 to type 2 and from type 2 to type 3, then we can use this knowledge to convert from type 1 to type 3. This can greatly decrease the number of coercion procedures we need to supply explicitly when we add a new type to the system. If we are willing to build the required amount of sophistication into our system, we can have it search the  "graph" of relations among types and automatically generate those coercion procedures that can be inferred from the ones that are suplied explicitly.

       On the other hand, there may be applications for which our coercion schemer is not general enough. Even when neither of the objects to be combined can be converted to the type of the other it may still be possible to perform the operation by converting both objects to a third type. In order to deal with such complexity and still preserve modularity in our programs, it is usually necessary to build systems that take advantage of still further structure in the relation among types, as we discuss next.

     * Hierarchies of types

       The coercion scheme presented above relied on the existence of natural relations between pairs of types. Often there is more "global" structure in how the different types related to each other.

       What we actually have is a so-called hierarchy of types.

       * tower

         The particular hierarchy we have here is of a very simple kind, in which each type has at most one supertype and at most one subtype. Such a structure, called a tower.

         If we have a tower strucutre, then we can greatly simplify the problem of adding a new type to the hierarchy, for we need only specify how the new type is embedded in the next supertype above it and how it is the supertype of the type blow it.

         Another advantage of a tower is that we can easily implement the notion that every type "inherits" all operations define on a supertype.

         Yet another advantage of a tower over a more general hierarchy is that it gives us a simple way to "lower" a data object to the simplest representation.

       * Inadequacies of hierarchies

         If the data types in our system can be naturally arranged in a tower this greatly simplifies the problems of dealing with generic operations on different types, as we have seen. Unfortunatyly, this is usually not he case.

         Dealing with large numbers of interrelated types while still preserving modularity in the desing of large systems is very difficult, and is an area of much current research.

         This statement, which also appears in the first edition of this book, is just as true now as it was when we wrote it twelve years ago. Developing a useful, general framework for expressing the relations among different types of entities (what philosophers call "ontology") seems intractably difficult. The main difference between the confustion that existed ten years ago and the confusion that exists now is that now a veriety of inadequate ontological theories have been embodied in a plethora of corresponding inadequate programming languages. For example, much of the complexity of of object-oriented programming languages -- and the subtle and confusing differences amoung contemporary object-oriented languages -- centers on the treatment of generic operations on interrelated types. Our own discussion of computational objects in Chapter 3 avoids these issues entirely. Readers familiar with object-oriented programming will notice that we have much to say in chapter 3 about local state, but we do not even mention "classes" or "inheritance". In fact, we suspect that these problems cannot be adequatly addressed in terms of computer-language design alone, without also drawing on work in knowledge representation and automated reasoning.

* Modularity, Object, and State
* Metalinguistic Abstraction
* Computing with Register Machines
